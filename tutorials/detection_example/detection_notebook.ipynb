{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Rex Omni Object Detection Tutorial\n",
    "\n",
    "This notebook demonstrates how to use Rex Omni for object detection tasks. Rex Omni is a high-level wrapper for multimodal language models that supports various vision tasks including object detection, keypoint detection, OCR, and visual prompting.\n",
    "\n",
    "## Features\n",
    "- Easy-to-use API with automatic model initialization\n",
    "- Support for both Transformers and VLLM backends\n",
    "- Built-in visualization capabilities with skeleton drawing for keypoints\n",
    "- Flexible configuration options\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Installation\n",
    "\n",
    "First, make sure you have Rex Omni installed. If not, you can install it using:\n",
    "\n",
    "```bash\n",
    "pip install rex_omni\n",
    "```\n",
    "\n",
    "Or install from source:\n",
    "```bash\n",
    "git clone https://github.com/IDEA-Research/Rex-Omni.git\n",
    "cd Rex-Omni\n",
    "pip install -e .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from PIL import Image\n",
    "from rex_omni import RexOmniWrapper, RexOmniVisualize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 1: Initialize Rex Omni Model\n",
    "\n",
    "Rex Omni automatically handles model and processor initialization. You just need to specify the model path and backend type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Rex Omni wrapper\n",
    "model_path = \"IDEA-Research/Rex-Omni\"  # Replace with your model path\n",
    "\n",
    "print(\"üöÄ Initializing Rex Omni model...\")\n",
    "\n",
    "rex_model = RexOmniWrapper(\n",
    "    model_path=model_path,\n",
    "    backend=\"transformers\",  # Choose \"transformers\" or \"vllm\"\n",
    "    max_tokens=2048,\n",
    "    temperature=0.0,\n",
    "    top_p=0.05,\n",
    "    top_k=1,\n",
    "    repetition_penalty=1.05,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 2: Load and Display Input Image\n",
    "\n",
    "Let's load an image for object detection. You can replace this with your own image path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "image_path = \"examples/test_images/cafe.jpg\"  # Replace with your image path\n",
    "\n",
    "try:\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    print(f\"‚úÖ Image loaded successfully!\")\n",
    "    print(f\"üìè Image size: {image.size}\")\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Input Image for Object Detection')\n",
    "    plt.show()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Image not found at: {image_path}\")\n",
    "    print(\"Please update the image_path variable with a valid image path\")\n",
    "    \n",
    "    # Create a dummy image for demonstration\n",
    "    print(\"Creating a dummy image for demonstration...\")\n",
    "    image = Image.new('RGB', (640, 480), color='lightblue')\n",
    "    print(\"‚úÖ Using dummy image\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 3: Define Categories to Detect\n",
    "\n",
    "Specify the object categories you want to detect in the image. Rex Omni can detect a wide variety of objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categories to detect\n",
    "categories = [\n",
    "    \"man\",\n",
    "    \"woman\", \n",
    "    \"yellow flower\",\n",
    "    \"sofa\",\n",
    "    \"robot-shope light\",\n",
    "    \"blanket\",\n",
    "    \"microwave\",\n",
    "    \"laptop\",\n",
    "    \"cup\",\n",
    "    \"white chair\",\n",
    "    \"lamp\",\n",
    "]\n",
    "\n",
    "print(\"üéØ Categories to detect:\")\n",
    "for i, category in enumerate(categories, 1):\n",
    "    print(f\"  {i}. {category}\")\n",
    "\n",
    "print(f\"\\nüìä Total categories: {len(categories)}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 4: Run Object Detection\n",
    "\n",
    "Now let's run the object detection inference using Rex Omni.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run object detection inference\n",
    "print(\"üîç Running object detection...\")\n",
    "\n",
    "results = rex_model.inference(\n",
    "    images=image, \n",
    "    task=\"detection\", \n",
    "    categories=categories\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Inference completed!\")\n",
    "\n",
    "# Display results\n",
    "result = results[0]\n",
    "if result[\"success\"]:\n",
    "    predictions = result[\"extracted_predictions\"]\n",
    "    raw_output = result[\"raw_output\"]\n",
    "    \n",
    "    print(f\"üéØ Found {sum(len(preds) for preds in predictions.values())} objects\")\n",
    "    print(\"\\nüìã Detection Results:\")\n",
    "    \n",
    "    for category, detections in predictions.items():\n",
    "        if detections:\n",
    "            print(f\"\\n  {category.upper()}:\")\n",
    "            for i, detection in enumerate(detections):\n",
    "                coords = detection.get(\"coords\", [])\n",
    "                if len(coords) == 4:\n",
    "                    x0, y0, x1, y1 = coords\n",
    "                    print(f\"    Box {i+1}: ({x0:.1f}, {y0:.1f}, {x1:.1f}, {y1:.1f})\")\n",
    "else:\n",
    "    print(f\"‚ùå Inference failed: {result['error']}\")\n",
    "    print(\"Raw output:\", result.get('raw_output', 'No output available'))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5: Visualize Results\n",
    "\n",
    "Rex Omni provides built-in visualization capabilities with support for skeleton drawing for keypoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize detection results\n",
    "if result[\"success\"] and predictions:\n",
    "    print(\"üé® Creating visualization...\")\n",
    "    \n",
    "    # Create visualization using Rex Omni's built-in function\n",
    "    vis_image = RexOmniVisualize(\n",
    "        image=image,\n",
    "        predictions=predictions,\n",
    "        font_size=20,\n",
    "        draw_width=5,\n",
    "        show_labels=True,\n",
    "    )\n",
    "    \n",
    "    # Display the visualization\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(vis_image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Object Detection Results', fontsize=16, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save visualization (optional)\n",
    "    try:\n",
    "        output_path = \"detection_results.jpg\"\n",
    "        vis_image.save(output_path)\n",
    "        print(f\"üíæ Visualization saved to: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not save image: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No predictions to visualize\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Advanced Usage\n",
    "\n",
    "### Using VLLM Backend for Faster Inference\n",
    "\n",
    "For faster inference, you can use the VLLM backend:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using VLLM backend (commented out - uncomment to use)\n",
    "# rex_model_vllm = RexOmniWrapper(\n",
    "#     model_path=\"IDEA-Research/Rex-Omni\",\n",
    "#     backend=\"vllm\",  # Use VLLM for faster inference\n",
    "#     max_tokens=2048,\n",
    "#     temperature=0.0,\n",
    "#     top_p=0.05,\n",
    "#     top_k=1,\n",
    "#     repetition_penalty=1.05,\n",
    "#     # VLLM-specific parameters\n",
    "#     gpu_memory_utilization=0.8,\n",
    "#     tensor_parallel_size=1,\n",
    "# )\n",
    "\n",
    "print(\"üí° VLLM backend provides faster inference for production use cases\")\n",
    "print(\"üí° Uncomment the code above to use VLLM instead of transformers\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Other Supported Tasks\n",
    "\n",
    "Rex Omni supports various vision tasks beyond object detection:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of other supported tasks (commented out)\n",
    "\n",
    "# 1. Keypoint Detection with Skeleton Visualization\n",
    "# keypoint_results = rex_model.inference(\n",
    "#     images=image,\n",
    "#     task=\"keypoint\",\n",
    "#     categories=[\"person\"]\n",
    "# )\n",
    "\n",
    "# 2. OCR with Bounding Boxes\n",
    "# ocr_results = rex_model.inference(\n",
    "#     images=image,\n",
    "#     task=\"ocr_box\",\n",
    "#     categories=[\"text\"]\n",
    "# )\n",
    "\n",
    "# 3. Visual Prompting (Point-based)\n",
    "# pointing_results = rex_model.inference(\n",
    "#     images=image,\n",
    "#     task=\"pointing\",\n",
    "#     categories=[\"object at point\"]\n",
    "# )\n",
    "\n",
    "print(\"üìù Supported tasks:\")\n",
    "print(\"  ‚Ä¢ detection - Object detection with bounding boxes\")\n",
    "print(\"  ‚Ä¢ keypoint - Keypoint detection with skeleton visualization\")\n",
    "print(\"  ‚Ä¢ ocr_box - OCR with bounding boxes\")\n",
    "print(\"  ‚Ä¢ pointing - Visual prompting with points\")\n",
    "print(\"  ‚Ä¢ visual_prompting - Advanced visual prompting\")\n",
    "\n",
    "print(\"\\nüé® Visualization features:\")\n",
    "print(\"  ‚Ä¢ Automatic skeleton drawing for keypoints\")\n",
    "print(\"  ‚Ä¢ Color-coded bounding boxes\")\n",
    "print(\"  ‚Ä¢ Category labels\")\n",
    "print(\"  ‚Ä¢ Customizable fonts and line widths\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated how to:\n",
    "\n",
    "1. **Initialize Rex Omni** with custom parameters\n",
    "2. **Load and prepare images** for inference\n",
    "3. **Run object detection** with specified categories\n",
    "4. **Visualize results** with built-in functions including skeleton drawing for keypoints\n",
    "5. **Use advanced features** like VLLM backend for faster inference\n",
    "\n",
    "### Key Features Highlighted:\n",
    "\n",
    "- **Easy API**: Simple initialization and inference calls\n",
    "- **Flexible Backends**: Support for both Transformers and VLLM\n",
    "- **Rich Visualizations**: Automatic skeleton drawing for keypoints, color-coded boxes, and labels\n",
    "- **Multiple Tasks**: Detection, keypoint detection, OCR, and visual prompting\n",
    "- **Customizable**: Adjustable inference parameters and visualization options\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Try different tasks (keypoint, OCR, visual prompting)\n",
    "- Experiment with VLLM backend for production use\n",
    "- Customize visualization parameters\n",
    "- Use your own images and categories\n",
    "\n",
    "For more information, check the [Rex Omni documentation](https://github.com/IDEA-Research/Rex-Omni) and examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rex Omni Object Detection Tutorial\n",
    "\n",
    "This notebook demonstrates how to use Rex Omni for object detection tasks (tasks that output in box format)\n",
    "\n",
    "## Features\n",
    "- Easy-to-use API with automatic model initialization\n",
    "- Support for both Transformers and VLLM backends\n",
    "- Built-in visualization capabilities\n",
    "- Flexible configuration options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Rex Omni Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'visualize_predictions' from 'rex_omni' (/comp_robot/jiangqing/projects/2023/research/R1/QwenSFTOfficial/open_source/rex_omni/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrex_omni\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RexOmniWrapper, visualize_predictions\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'visualize_predictions' from 'rex_omni' (/comp_robot/jiangqing/projects/2023/research/R1/QwenSFTOfficial/open_source/rex_omni/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from PIL import Image\n",
    "from rex_omni import RexOmniWrapper, visualize_predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Rex-Omni supports both Transformers and VLLM backends by switching the backend parameter.\n",
    "model_path = \"IDEA-Research/Rex-Omni\"  # Replace with your model path\n",
    "\n",
    "print(\"üöÄ Initializing Rex Omni model...\")\n",
    "\n",
    "rex_model = RexOmniWrapper(\n",
    "    model_path=model_path,\n",
    "    backend=\"transformers\",  # Choose \"transformers\" or \"vllm\"\n",
    "    max_tokens=2048,\n",
    "    temperature=0.0,\n",
    "    top_p=0.05,\n",
    "    top_k=1,\n",
    "    repetition_penalty=1.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Object Detection Example\n",
    "\n",
    "Let's load an image for object detection task. You can replace this with your own image path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "image_path = \"examples/test_images/cafe.jpg\"  # Replace with your image path\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "print(f\"‚úÖ Image loaded successfully!\")\n",
    "print(f\"üìè Image size: {image.size}\")\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title('Input Image for Object Detection')\n",
    "plt.show()\n",
    "\n",
    "# Define categories to detect\n",
    "categories = [\n",
    "    \"man\",\n",
    "    \"woman\",\n",
    "    \"yellow flower\",\n",
    "    \"sofa\",\n",
    "    \"robot-shope light\",\n",
    "    \"blanket\",\n",
    "    \"microwave\",\n",
    "    \"laptop\",\n",
    "    \"cup\",\n",
    "    \"white chair\",\n",
    "    \"lamp\",\n",
    "]\n",
    "\n",
    "# inference\n",
    "results = rex_model.inference(images=image, task=\"detection\", categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets visualize the predicted results using RexOmniVisualize function"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "result = results[0]\n",
    "if result[\"success\"]:\n",
    "    predictions = result[\"extracted_predictions\"]\n",
    "    vis_image = visualize_predictions(\n",
    "        image=image,\n",
    "        predictions=predictions,\n",
    "        font_size=20,\n",
    "        draw_width=5,\n",
    "        show_labels=True,\n",
    "    )\n",
    "    # display the visualization\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(vis_image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Object Detection Visualization')\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"Inference failed: {result['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
